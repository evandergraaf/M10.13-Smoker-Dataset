{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ffe7d6-3fc3-4103-aeab-6462041dfa83",
   "metadata": {},
   "source": [
    "# Smoker Dataset\n",
    "## Module 10.13 Assignment 10: Final Project\n",
    "Dec. 2024\n",
    "\n",
    "Authors: Tyler Earps, Ryan Smith, Basil Mullings, & Ean Vandergraaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502a707-bc32-46a2-824b-576109d17d29",
   "metadata": {},
   "source": [
    "### Abstract and Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7bd0f-3f3d-4289-ae4e-d35fcda9ec80",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/playground-series-s3e24/data?select=train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f66c04-9823-4c3e-bba6-71eb6dd99e47",
   "metadata": {},
   "source": [
    "### Stage 0: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e3680-72de-4f5b-965b-ff90a9e9f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlod the data\n",
    "# https://www.kaggle.com/competitions/playground-series-s3e24/data?select=train.csv\n",
    "\n",
    "# Extract train.csv & test.csv to folder \"./Data\" in the same directory as repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe58c92-b8c2-4ef1-9bb0-98f22c136c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import count, countDistinct, format_number, when, col, explode, lower\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#Load Kaggle data into a DataFrame\n",
    "def csvToDF(fileName):\n",
    "    return spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option('escape','\"')\\\n",
    "                .load(fileName)\n",
    "    \n",
    "df_train = csvToDF(\"data/train.csv\")\n",
    "df_test = csvToDF(\"data/test.csv\")\n",
    "\n",
    "#Cast all columns to double\n",
    "df_train = df_train.select([col(column).cast('double') for column in df_train.columns])\n",
    "df_test = df_test.select([col(column).cast('double') for column in df_test.columns])\n",
    "\n",
    "##Show our basic statistics\n",
    "print('#=> Summary of statistics for our Training data :')\n",
    "df_train.summary().show()\n",
    "print(\"\\n\")\n",
    "\n",
    "##Show the data schema\n",
    "print('#=> Training data schema:')\n",
    "df_train.printSchema()\n",
    "print(\"\\n\")\n",
    "\n",
    "##List the column names \n",
    "print('#=> Column names:')\n",
    "print(df_train.columns)\n",
    "print(\"\\n\")\n",
    "\n",
    "##Verify any null relevant data in any of our columns.\n",
    "print('#=> Training dataset with Null values:')\n",
    "df_train.select([count(when(col(c).isNull(), c )).alias(c) for c in df_train.columns]).show()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3307e-d96a-43aa-8fc3-b51ec0f78cca",
   "metadata": {},
   "source": [
    "### Stage 1: Data Preparation\n",
    "\n",
    "<i>EDA & Any adjustments to clean the data</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547c6f6-ccb9-4d2d-abe4-50e7f5524bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Find most important features\n",
    "# Do some box and whisker charts\n",
    "# Decide if any transformations need to be made\n",
    "\n",
    "df_train.describe().show()\n",
    "\n",
    "def box_chart(df, title):\n",
    "    plt.figure(figsize=(len(df.columns)*2, 6))\n",
    "    sns.boxplot(data=df)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "## Distributions\n",
    "print('Distributions within the dataset')\n",
    "df_train_age = df_train.select('age').toPandas()\n",
    "box_chart(df_train_age,\"Distributions of Age\")\n",
    "\n",
    "df_train_measurements = df_train.select('height(cm)', 'weight(kg)', 'waist(cm)').toPandas()\n",
    "box_chart(df_train_measurements,\"Distributions of Measurements\")\n",
    "\n",
    "df_train_senses = df_train.select('eyesight(left)', 'eyesight(right)', 'hearing(left)', 'hearing(right)').toPandas()\n",
    "box_chart(df_train_senses,\"Distributions of Senses\")\n",
    "\n",
    "df_train_lifestyle = df_train.select('systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride').toPandas()\n",
    "box_chart(df_train_lifestyle,\"Distributions of Lifestyle Factors\")\n",
    "\n",
    "## Binary Analysis\n",
    "df_train_smokers = df_train.filter('smoking == 1').count()\n",
    "df_train_non_smokers = df_train.filter('smoking == 0').count()\n",
    "y = np.array([df_train_smokers, df_train_non_smokers])\n",
    "labels = ['Smokers', 'Non-Smokers']\n",
    "plt.title('Breakdown of Smokers vs Non-Smokers in Data')\n",
    "plt.pie(y, labels = labels, startangle=90)\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe32ba3-47da-49c4-8941-4b75861214d5",
   "metadata": {},
   "source": [
    "### Stage 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aec42-13c6-4a37-8bb3-2e3a24a36bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "# Split data from label\n",
    "x_features = ['age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'eyesight(left)', 'eyesight(right)', 'hearing(left)', 'hearing(right)', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride', 'HDL', 'LDL', 'hemoglobin', 'Urine protein', 'serum creatinine', 'AST', 'ALT', 'Gtp', 'dental caries']\n",
    "y_features = ['smoking']\n",
    "\n",
    "# df_train_x = df_train.select(x_features)\n",
    "# df_train_y = df_train.select(y_features)\n",
    "# Scale the data\n",
    "\n",
    "# Use FeatureHasher to combine features into one column\n",
    "hasher = FeatureHasher()\n",
    "hasher.setInputCols(x_features)\n",
    "hasher.setOutputCol(\"features\")\n",
    "df_train_x = hasher.transform(df_train.withColumn(\"label\", df_train.smoking))\n",
    "df_train_x = df_train_x.select(['features', 'label'])\n",
    "\n",
    "df = df_train_x.select(concat(df_train_x.select('features')).alias('s'))\n",
    "df.collect()\n",
    "\n",
    "# Now display 2 rows of the processed train data.\n",
    "print(\"\\n\")\n",
    "print('#=> Displaying processed train data:')\n",
    "df_train_x.show(n=2, truncate=False)\n",
    "\n",
    "# Use RandomForestClassifier for feature importance ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bdcbe-9874-46f8-8323-83729cd83af4",
   "metadata": {},
   "source": [
    "### Stage 3: Machine Learning Algorithm Preparation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f073f-dbf5-4ebd-a681-cc83a9649030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, NaiveBayes\n",
    "\n",
    "#=> Stage 3.7 - Perform our train/test split\n",
    "##Split the training data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test = df_train_x.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "##Our list of ML models\n",
    "ml_models = {\n",
    "    \"randomForest_model\": RandomForestClassifier(),\n",
    "    \"decisionTree_model\": DecisionTreeClassifier(),\n",
    "    \"logisticReg_model\": LogisticRegression(),\n",
    "    \"naive_bayes_model\": NaiveBayes(smoothing=0.5)\n",
    "}\n",
    "\n",
    "##Catalog the \"smoking\" prediction results of our models.\n",
    "results = {}\n",
    "for model_name, model in ml_models.items():\n",
    "    ##Proceed to train the model.\n",
    "    trained_model = model.fit(X_train)\n",
    "\n",
    "    ##Do the prediction\n",
    "    y_pred = trained_model.transform(X_test)\n",
    "\n",
    "    #=> Stage 3.8\n",
    "    ##Do the evaluation.\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(y_pred)\n",
    "    results[model_name] = { \"accuracy\": accuracy, \"y_pred\": y_pred }\n",
    "    print(f\"{model_name}: {accuracy=}\")\n",
    "\n",
    "    ##Check the predictions.\n",
    "    y_pred.select(\"label\", \"prediction\").show(5)\n",
    "\n",
    "highest_accuracy = 0\n",
    "best_performing_model = \"\"\n",
    "\n",
    "##Now traverse our results dictionary and find the highest accuracy of each of our model.\n",
    "for model_name, result in results.items():\n",
    "    if result[\"accuracy\"] > highest_accuracy:\n",
    "        highest_accuracy = result[\"accuracy\"]\n",
    "        best_model = model_name\n",
    "\n",
    "print(f'The Best performing model: {best_model}={highest_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52e1aa-45cc-4966-8d59-1d6f86787169",
   "metadata": {},
   "source": [
    "### Stage 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a84ed-50a9-4532-8d00-f4e9f1e61663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4113fb57-4c37-4e29-96c4-b603efab1c02",
   "metadata": {},
   "source": [
    "### Stage 5: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c29d8-6b58-4ed1-a3b8-eaca8e8a6cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b84a83-26e7-49db-8daa-11e8ba857f98",
   "metadata": {},
   "source": [
    "### Limitations, Future Work, and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d7de9-0e63-4938-8a5a-ad8b1de44149",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b26107-db3f-401e-85e0-48043cf2d839",
   "metadata": {},
   "source": [
    "### Overall Performance and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41194a3-f36c-4b96-8e37-b67ce2a57b40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
